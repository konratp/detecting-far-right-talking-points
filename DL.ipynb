{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed919ae1",
   "metadata": {},
   "source": [
    "# Deep Learning - NNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f7df8f",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3525d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8349311",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"PATH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9967ac73",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c822b7",
   "metadata": {},
   "source": [
    "### Train-test split: partial df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2049a0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first trial: # percent of the data \n",
    "\n",
    "if percentage_of_sentences is not None:\n",
    "        assert(percentage_of_sentences> 0 and percentage_of_sentences<=100)\n",
    "        \n",
    "        len_train = int(percentage_of_sentences/100*len(train_sentences))\n",
    "        train_sentences, y_train = train_sentences[:len_train], y_train[:len_train]\n",
    "  \n",
    "        len_test = int(percentage_of_sentences/100*len(test_sentences))\n",
    "        test_sentences, y_test = test_sentences[:len_test], y_test[:len_test]\n",
    "    \n",
    "    X_train = [text_to_word_sequence(_.decode(\"utf-8\")) for _ in train_sentences]\n",
    "    X_test = [text_to_word_sequence(_.decode(\"utf-8\")) for _ in test_sentences]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_data(percentage_of_sentences=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2efd8f",
   "metadata": {},
   "source": [
    "### Train-test split: full df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8e5f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03de8391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence length\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_hist(X):\n",
    "    len_ = [len(_) for _ in X]\n",
    "    plt.hist(len_)\n",
    "    plt.title('Histogram of the number of sentences that have a given number of words')\n",
    "    plt.show()\n",
    "    \n",
    "plot_hist(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1219e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the result of this check, we might want to update the padding maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66af544",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q: should one remove freq / rare words at this point? \n",
    "https://kitt.lewagon.com/camps/1014/lectures/content/06-DL_05-Natural-Language-Processing.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09928c86",
   "metadata": {},
   "source": [
    "## Embeddings: word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080466b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a sentence (list of words) into a matrix representing the words in the embedding space\n",
    "\n",
    "def embed_sentence(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec.wv:\n",
    "            embedded_sentence.append(word2vec.wv[word])\n",
    "        \n",
    "    return np.array(embedded_sentence)\n",
    "\n",
    "# Function that converts a list of sentences into a list of matrices\n",
    "def embedding(word2vec, sentences):\n",
    "    embed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence(word2vec, sentence)\n",
    "        embed.append(embedded_sentence)\n",
    "        \n",
    "    return embed\n",
    "\n",
    "# Embed the training and test sentences\n",
    "X_train_embed = embedding(word2vec, X_train)\n",
    "X_test_embed = embedding(word2vec, X_test)\n",
    "\n",
    "\n",
    "# Pad the training and test embedded sentences\n",
    "X_train_pad = pad_sequences(X_train_embed, dtype='float32', padding='post', maxlen=200)\n",
    "X_test_pad = pad_sequences(X_test_embed, dtype='float32', padding='post', maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95678807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining word2vec\n",
    "\n",
    "word2vec = Word2Vec(sentences=X_train, vector_size=60, min_count=10, window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137a6aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST ME\n",
    "\n",
    "for X in [X_train_pad, X_test_pad]:\n",
    "    assert type(X) == np.ndarray\n",
    "    assert X.shape[-1] == word2vec.wv.vector_size\n",
    "\n",
    "\n",
    "assert X_train_pad.shape[0] == len(X_train)\n",
    "assert X_test_pad.shape[0] == len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6100549f",
   "metadata": {},
   "source": [
    "### Exploring the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d1d769",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.most_similar(\"fascist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff645f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding = wv['fascist']\n",
    "wv.similar_by_vector(word_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408a3a48",
   "metadata": {},
   "source": [
    "## Modeling pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4965ba7c",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c78ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "counts = dict(zip(unique, counts))\n",
    "print('Number of labels in train set', counts)\n",
    "\n",
    "y_pred = 0 if counts[0] > counts[1] else 1\n",
    "\n",
    "print('Baseline accuracy: ', accuracy_score(y_test, [y_pred]*len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8493c7f7",
   "metadata": {},
   "source": [
    "### word2vec +  RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3390f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of your embedding space = size of the vector representing each word\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e056fc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Masking())\n",
    "    model.add(layers.LSTM(20, activation='tanh'))\n",
    "    model.add(layers.Dense(15, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54a252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train_pad, y_train, \n",
    "          batch_size = 32,\n",
    "          epochs=100,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[es]\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5112110",
   "metadata": {},
   "source": [
    "### Using CNNs [1D convolutions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72df18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv1D\n",
    "\n",
    "cnn = Sequential([\n",
    "    layers.Embedding(input_dim=5000, input_length=20, output_dim=30, mask_zero=True),\n",
    "    layers.Conv1D(20, kernel_size=3),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1, activation=\"sigmoid\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8fc60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = Sequential([\n",
    "    layers.Embedding(input_dim=5000, input_length=20, output_dim=30, mask_zero=True),\n",
    "    layers.LSTM(20),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edea9bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cd1764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac545ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2df7d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d025b508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
