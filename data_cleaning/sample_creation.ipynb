{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3fc9cc1",
   "metadata": {},
   "source": [
    "# Balancing & Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cdb85c",
   "metadata": {},
   "source": [
    "In order to accurately train a deep learning model, it is often not enough to simply train it on a complete dataset and expect it to be able to make accurate predictions. Rather, it is important to account for potential biases in the underlying data, and train a model on a more balanced dataset.\n",
    "\n",
    "Because most Members of the European Parliament (MEP) are members of conservative, left-wing, environmentalist or liberal parties, it is only natural that most speeches in the European Parliament are not given by right-wing populists, but rather politicians from a variety of ideological backgrounds. Since our goal is to train a deep learning classifier to accurately predict whether a given speech was given by a right-wing populist MEP or not, training it on the original, unbalanced data would likely not yield satisfying results. Since only about 15% of the speeches in our dataset were given by right-wing populists, a model trained on the unbalanced, original dataset could, at an accuracy of 85%, just predict every speech not to be given by a right-wing populist MEP. \n",
    "\n",
    "To avoid such an outcome, we instead want to train the model on balanced data. In this notebook, we transform our dataset to become more balanced. We use three different approaches for this: downsampling, upsampling, and synthetic sampling. To reproduce the results of our project, we recommend running the code below to retrace our steps and understand the conceptual differences between the three balancing approaches before moving on to the notebooks training our BERT classifier and performing topic modeling. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6d680a",
   "metadata": {},
   "source": [
    "## Preparing the Dataset\n",
    "\n",
    "In the first few cells of code, we load required packages as well as the dataset resulting from cleaning and preprocessing steps taken in the [`data_cleaning` notebook](data_cleaning_preprocessing.ipynb). Please make sure to read in the cleaned and preprocessed data here. After reading in the data frame, we split the data into a test and train set, as we do **not** want to balance the test data, only the training set. If you choose to do so, you can save the test set as a `.csv` file by uncommenting the relevant line of code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ba980c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "503ae349",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data frame\n",
    "path = f\"{os.getcwd()}\"\n",
    "data = pd.read_csv(f\"{path}/final_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5ee317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train and test sets\n",
    "X = data[['contribution_text']]\n",
    "y = data['far_right']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "#join X_train and y_train\n",
    "data = X_train.join(y_train)\n",
    "\n",
    "#join X_test and y_test\n",
    "test = X_test.join(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03bc8a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment the following line to save test set to csv file\n",
    "#test.to_csv(f\"{path}/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295e43b8",
   "metadata": {},
   "source": [
    "## Downsampling\n",
    "\n",
    "One approach to balancing a dataset is to downsample it. After performing a value count of the target variable, `far_right`, we see that there are roughly 17,000 speeches given by right-wing populists in the dataset. In order to balance the data, we then take a random sample of roughly 34,000 speeches where `far_right` = 0, and create a new data frame where 1/3 of speeches come from far-right MEPs, and 2/3 of speeches do not. This way, we maintain the trend that the majority of speeches are not given by far-right Members of the European Parliament, without allowing for our model to predict the target variable to be 0 across the board. You can save the resulting data frame as a `.csv` file by uncommenting the relevant line of code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c7eaeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of speeches given by non-far-right MEP is 82339, while the number of speeches given by far-right MEP is 17520.\n"
     ]
    }
   ],
   "source": [
    "#split data into two groups based on y variable\n",
    "category_0 = data[data['far_right'] == 0]\n",
    "category_1 = data[data['far_right'] == 1]\n",
    "print(f\"The number of speeches given by non-far-right MEP is {len(category_0)}, while the number of speeches given by far-right MEP is {len(category_1)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23be974c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    35040\n",
       "1    17520\n",
       "Name: far_right, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reduce number of speeches where far_right = 0 -- create a dataset with 1/3 far_right = 1, 2/3 far_right = 0\n",
    "cat_0_sample = category_0.sample(len(category_1)*2)\n",
    "d_sample = pd.concat([cat_0_sample, category_1], axis=0)\n",
    "d_sample['far_right'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d64316c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment the following line to save downsampled data to csv file\n",
    "#d_sample.to_csv(f\"{path}/downsample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b650ff4",
   "metadata": {},
   "source": [
    "## Upsampling \n",
    "\n",
    "Upsampling is another approach to balancing a dataset. Instead of removing observations of the majority category from the data frame, observations from the minority category are duplicated in order to create a better balance in the target variable. The resulting data frame contains 70,080 speeches that were given far-right MEP, and 82,339 speeches that were given by MEP from other ideological backgrounds. Again, you can save the resulting data frame as a `.csv` file by uncommenting the relevant line of code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88a9a84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_1_usample = pd.concat([category_1, category_1], axis = 0)\n",
    "u_sample_1 = pd.concat([cat_1_usample, cat_1_usample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "553a39d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    82339\n",
       "1    70080\n",
       "Name: far_right, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_sample = pd.concat([u_sample_1, category_0], axis = 0)\n",
    "u_sample['far_right'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42ca3cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment the following line to save downsampled data frame to csv file\n",
    "#u_sample.to_csv(f\"{path}/upsample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e07c27",
   "metadata": {},
   "source": [
    "## Synthetic Sampling\n",
    "\n",
    "The final approach to balancing the dataset involves synthetic sampling. To do this, we split each contribution into individual sentences, and try to create new observations from these sentences that are shorter in length and thus more plentiful than the previous subsets of data for which `far_right` = 1. Keep in mind that this process is only done in order to train the model, not to test its performance. While relevant metadata is lost in the training process, it has no impact on the model's evaluation of a speech it hasn't seen before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daecd134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of all sentences in the data set\n",
    "list_of_sentences = []\n",
    "\n",
    "for i in category_1.contribution_text:\n",
    "    k = nltk.tokenize.sent_tokenize(i)\n",
    "    for j in k:\n",
    "        list_of_sentences.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e7505b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185870"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check how many sentences are present in the data set\n",
    "len(list_of_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc3bc935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.609018264840183"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check average number of sentences per contribution\n",
    "len(list_of_sentences) / len(category_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00179fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1478.615011415525"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check average number of characters per contribution\n",
    "avg_length = np.mean(category_1.contribution_text.map(len))\n",
    "avg_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffc8d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomize list of sentences\n",
    "random_list_of_sentences = random.sample(list_of_sentences, len(list_of_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f9879ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary that reassembles sentences and synthesizes new observations -- triple number of obs where far_right = 1\n",
    "\n",
    "synth_dict = {}\n",
    "list_of_charcounts = []\n",
    "\n",
    "for i in range(len(category_1) * 3):\n",
    "    sample = []\n",
    "    char_count = 0\n",
    "    for j in range(10):\n",
    "        rand_idx = random.randint(0, len(category_1)-1)\n",
    "        sentence = random_list_of_sentences[rand_idx]\n",
    "        sample.append(sentence)\n",
    "        char_count += len(sentence)\n",
    "    if char_count < avg_length:\n",
    "        rand_idx = random.randint(0, len(category_1)-1)\n",
    "        sample.append(random_list_of_sentences[rand_idx])\n",
    "        char_count += len(random_list_of_sentences[rand_idx])\n",
    "    list_of_charcounts.append(char_count)\n",
    "    synth_dict[i] = [sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0eea6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.702245053272463"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check difference in average number of characters per observation\n",
    "avg_length - np.mean(list_of_charcounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca9ba56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe based on the synth sample dictionary\n",
    "s_sample_1 = pd.DataFrame.from_dict(synth_dict).T\n",
    "s_sample_1['far_right'] = 1\n",
    "s_sample_1 = s_sample_1.rename(columns = {0: 'contribution_text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb000047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shorten cat_0 data frame to be able to concat later on\n",
    "cat_0_short = category_0[['contribution_text', 'far_right']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "171659b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate newly synthesized rows with previously existing rows where far_right = 0, shuffle and reset index\n",
    "s_sample = pd.concat([cat_0_short, s_sample_1], axis = 0)\n",
    "s_sample = s_sample.sample(frac = 1)\n",
    "s_sample.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "153d952d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    82339\n",
       "1    52560\n",
       "Name: far_right, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check value counts of far_right column\n",
    "s_sample['far_right'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44df49ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataframe to csv\n",
    "#s_sample.to_csv(f\"{path}/synthsample.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
